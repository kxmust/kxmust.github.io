<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ken</title><link>https://kxmust.github.io</link><description>乐观是一种生活态度，保持学习和记录。</description><copyright>Ken</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://avatars.githubusercontent.com/u/99197662?v=4</url><title>avatar</title><link>https://kxmust.github.io</link></image><lastBuildDate>Wed, 23 Apr 2025 09:26:55 +0000</lastBuildDate><managingEditor>Ken</managingEditor><ttl>60</ttl><webMaster>Ken</webMaster><item><title>深度学习4-数值稳定性优化(权重初始化和激活函数的选择)</title><link>https://kxmust.github.io/post/shen-du-xue-xi-4--shu-zhi-wen-ding-xing-you-hua-%28-quan-zhong-chu-shi-hua-he-ji-huo-han-shu-de-xuan-ze-%29.html</link><description># 数值稳定性
在模型训练过程中，计算梯度是可以理解为多个矩阵的乘法，当网络模型很深时，如果每个矩阵中的值都大于0，这样就会让梯度变得非常大，导致梯度爆炸，这对模型的训练来说是致命的。</description><guid isPermaLink="true">https://kxmust.github.io/post/shen-du-xue-xi-4--shu-zhi-wen-ding-xing-you-hua-%28-quan-zhong-chu-shi-hua-he-ji-huo-han-shu-de-xuan-ze-%29.html</guid><pubDate>Wed, 23 Apr 2025 09:26:29 +0000</pubDate></item><item><title>深度学习3-多层感知机</title><link>https://kxmust.github.io/post/shen-du-xue-xi-3--duo-ceng-gan-zhi-ji.html</link><description># 多层感知机
## 1 感知机
1. 感知机是一个二分类模型，输出0或者1(或者-1,1)，是最早的AI模型之一。</description><guid isPermaLink="true">https://kxmust.github.io/post/shen-du-xue-xi-3--duo-ceng-gan-zhi-ji.html</guid><pubDate>Tue, 22 Apr 2025 08:04:43 +0000</pubDate></item><item><title>深度学习2-Softmax回归(常见的损失函数，Fashion-MNIST)</title><link>https://kxmust.github.io/post/shen-du-xue-xi-2-Softmax-hui-gui-%28-chang-jian-de-sun-shi-han-shu-%EF%BC%8CFashion-MNIST%29.html</link><description># Softmax回归

softmax回归其实是一个分类问题。</description><guid isPermaLink="true">https://kxmust.github.io/post/shen-du-xue-xi-2-Softmax-hui-gui-%28-chang-jian-de-sun-shi-han-shu-%EF%BC%8CFashion-MNIST%29.html</guid><pubDate>Mon, 21 Apr 2025 12:23:26 +0000</pubDate></item><item><title>深度学习1-线性回归</title><link>https://kxmust.github.io/post/shen-du-xue-xi-1--xian-xing-hui-gui.html</link><description># 线性回归
利用一个简单的线性回归的例子来了解神经网络的实现逻辑。</description><guid isPermaLink="true">https://kxmust.github.io/post/shen-du-xue-xi-1--xian-xing-hui-gui.html</guid><pubDate>Fri, 18 Apr 2025 09:15:23 +0000</pubDate></item></channel></rss>